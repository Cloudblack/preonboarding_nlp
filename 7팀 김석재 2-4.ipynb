{"cells":[{"cell_type":"markdown","metadata":{"id":"592U6lXs3d2t"},"source":["# Week2_4 Assignment\n","\n","## [BASIC](#Basic) \n","- 커스텀 모듈(`helper.py`)에서 **클래스와 함수를 임포트**할 수 있다.\n","- **autograd**의 개념 복습\n","\n","\n","## [CHALLENGE](#Challenge)\n","- train() 함수에 **epoch, scheduler, grad_clipping**을 추가할 수 있다.\n","- **validate() 함수를 구현**할 수 있다.\n","\n","\n","## [ADVANCED](#Advanced)\n","- train() 함수를 사용해 데이터를 **4 epoch 학습**할 수 있다. \n","- **predict 함수를 구현**할 수 있다. \n","- **evaluation metric 구현**할 수 있다. \n","    - accuracy\n","\n","\n","\n","### Reference\n","- [Pytorch Autograd Explain official document](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:47.370876Z","start_time":"2022-02-02T04:01:46.520392Z"},"id":"KSX-wQA1RD1h"},"outputs":[],"source":["import os\n","import sys\n","import pandas as pd\n","import numpy as np \n","import torch\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:47.375658Z","start_time":"2022-02-02T04:01:47.372242Z"},"id":"MH7RJjtZXOHf"},"outputs":[],"source":["# set seed\n","seed = 7777\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","source":[""],"metadata":{"id":"BFjhBJPdD-Ha"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:07:00.849353Z","start_time":"2022-01-31T13:06:56.187962Z"},"id":"62plMahMWr0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299382847,"user_tz":-540,"elapsed":10750,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"f4313870-fb5c-4ded-a384-c30f562d3746"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.6 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 31.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 33.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.16.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WagJcj-Ud4L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299409969,"user_tz":-540,"elapsed":16804,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"f3465704-f059-44f4-e963-8b662bd817cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from google.colab import files #뭐가 문제인지 구글드라이브를 통해 업로드한게 안먹혀서 직접 업로드했다\n","src = list(files.upload().values())[0] \n","open('helper.py','wb').write(src) \n"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":98},"id":"4hp8wNU35Em3","executionInfo":{"status":"ok","timestamp":1646299415272,"user_tz":-540,"elapsed":5308,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"0168094b-762f-44c7-820b-2a3b82fcabc7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-cb320194-a623-48f4-895a-f8ea0c1b476c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cb320194-a623-48f4-895a-f8ea0c1b476c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving helper.py to helper.py\n"]},{"output_type":"execute_result","data":{"text/plain":["3532"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnETqIqdVApF"},"outputs":[],"source":["# 어제 자신이 구현한 helper.py 모듈 경로를 입력\n","sys.path.append('/content/drive/MyDrive/AI/프리온보딩')"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:49.735578Z","start_time":"2022-02-02T04:01:49.475969Z"},"id":"N84mZeYMUFxJ","executionInfo":{"status":"ok","timestamp":1646299419930,"user_tz":-540,"elapsed":4661,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["fb56d92e7fad4206a5d02bb72e37e8e4","907ec485efa34068a0d7e35d533baf79","3602f5deadef4d7daffeee229663361d","111c7e7402514c7b9ef6ece192f52a01","57f850358d4b4e438684fb39a5ce02ab","0395996c354c45d3bc33b8984d4c44c9","778d829c34344c8a9cd6dd0f2dc7eaf7","ad8a84ee431044ce82ac5a5b2efe5777","01a4f5845e2f48f1b2fa3c8a64495482","2dba744c74ae4d1ebdc0c9d2a4feb5d6","fb5e02bad0dd442f939bada7421c4653","56ab89c5452d4135b07d2c1e24a44051","8ecd16f084494944833b53fed089275d","c05528d675cc4675bbe74db06b1791f1","34487c70973b46828a77658aec20ad24","dc90354839da45b9936cfbe04004a033","defb3edc5b3e4b73bd1f563330309d77","c21031be7a984593ad6f5fcc128da3bf","b9f3d805ae3946f595ca4fcaca393fe9","5c536f4c37cf4d89977975716388549e","519fb7be4c7340169ee89fb60d376f87","d808579114c54383b95d5c744bd3d6e2","3c9c122a8a4848208eeb1850e0a692ee","bb8654c144fa46a18358a7dbe80db675","9cb7c2e5f63c4238b354650f43c754e9","5ac52b403cdc469f9e5d7e06b563c1aa","823d7ae43042483c9b421ccc1188e835","3d75dcb8a53e494a92c34906c004ce03","fb80a428a04840bd8c88de5dfb94458e","27557c8a6d094261bff995a57e9ce34a","4ebf9df932b84ed5ac9e313568f31cf2","164da745095748e5bbdc97b8cb8504b9","dd4fd86cd33f4b84afcccec1c744b2e8","db6346723d1443b8a910b4c47ec68cb6","27113815b0694b78897bad22a06d9833","978b061973634d42b49a9e788ce85555","13d112fc5a7149b8a25c9fc275ba5c98","ac6acfec8de847b5b56940759b8742e9","185d8141487a4420afd47324bdc4add0","e205d0fc626a4643b1b467b54ad5ba96","982bfdd5b88442c8916c70975016b06a","ea900201c92e4a96863de226592232d7","d4918a0d230a4ad6974f202060057002","9361b99bab384ad3a5797164a3ee37e7","74629b4255a34da09920dbe94c4ff0c4","2d80c64b44254f5e9a283d97d017b037","1f538c6d6d194608b79e385538410053","cf423e8cc01d49f698f265bab62631d6","8a6e28e914de42d5bb952bb113da551f","4d3d9ae021764ab4abbaafe220ee35e6","010e81876d19415f978a4c3f802bb5fb","a79e710dae3d419494f71549c721ce61","f34b0237b30a42dfb767b4c4c27b2a31","b5b816392dce4f188995f430d3bffaeb","ba77ae9c18e645549e727b7dfd2744c0"]},"outputId":"af43693e-0fd9-4fd3-e2f6-533bc2acaa4a"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb56d92e7fad4206a5d02bb72e37e8e4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56ab89c5452d4135b07d2c1e24a44051","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c9c122a8a4848208eeb1850e0a692ee","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db6346723d1443b8a910b4c47ec68cb6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/483k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74629b4255a34da09920dbe94c4ff0c4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"]},"metadata":{}}],"source":["# helper 모듈을 import하면 이전에 구현했던 다양한 함수 및 클래스를 사용할 수 있음 \n","# 함수: set_device()\n","# 함수: custom_collate_fn() \n","# 클래스: CustomDataset\n","# 클래스: CustomClassifier\n","# 가 import 됨\n","from helper import *\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, random_split"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:49.771743Z","start_time":"2022-02-02T04:01:49.736866Z"},"id":"oR5EWmh5UFxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420204,"user_tz":-540,"elapsed":9,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"eb39c663-639b-4326-d8ab-6d00c12db2e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["# available GPUs : 1\n","GPU name : Tesla P100-PCIE-16GB\n","device: cuda\n"]}],"source":["# device\n","device =set_device()\n","print(f\"device: {device}\")"]},{"cell_type":"code","source":["device_cpu=torch.device('cpu') #cuda 메모리가 자꾸 아웃되서 학습이 끝날때마다 cpu로 옮겨주려고 만듬"],"metadata":{"id":"RYbcc8ETEBof"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkNxrCV45Q3m"},"source":["## Basic"]},{"cell_type":"markdown","metadata":{"id":"9YBUQykS5Q3n"},"source":["### 모듈에서 클래스와 함수를 임포트해 다음을 구현\n","- train_dataset, train_dataloader\n","- valid_dataset, valid_dataloader\n","- test_dataset, test_dataloader"]},{"cell_type":"code","source":["# train dataframe 다운로드\n","!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv"],"metadata":{"id":"cjNksUEwGACb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420483,"user_tz":-540,"elapsed":287,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"36d35f9d-bd69-4054-be7c-56d9e69a8faf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-03 09:23:36--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 971625 (949K) [text/plain]\n","Saving to: ‘sample_df.csv’\n","\n","sample_df.csv       100%[===================>] 948.85K  --.-KB/s    in 0.03s   \n","\n","2022-03-03 09:23:37 (27.6 MB/s) - ‘sample_df.csv’ saved [971625/971625]\n","\n"]}]},{"cell_type":"code","source":["# test dataframe 다운로드\n","!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv"],"metadata":{"id":"kXfk8ZEHGB0v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420784,"user_tz":-540,"elapsed":303,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"2f4ddd15-f18e-4dd6-913b-7d9b37afd22e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-03 09:23:37--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 101383 (99K) [text/plain]\n","Saving to: ‘sample_df_test.csv’\n","\n","sample_df_test.csv  100%[===================>]  99.01K  --.-KB/s    in 0.008s  \n","\n","2022-03-03 09:23:37 (11.6 MB/s) - ‘sample_df_test.csv’ saved [101383/101383]\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.037044Z","start_time":"2022-02-02T04:01:52.707669Z"},"id":"KVo5dPnmUFxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420785,"user_tz":-540,"elapsed":14,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"89b402c0-85ba-42aa-ab0e-1e8334a81fd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["train shape : (10000, 3)\n","test shape : (1000, 3)\n"]}],"source":["# 학습 & 평가 데이터셋 로드\n","# 학습 및 평가 샘플 데이터 개수는 각각 10,000개, 1,000개\n","\n","df_train = pd.read_csv('sample_df.csv')\n","df_test = pd.read_csv('sample_df_test.csv')\n","\n","print(f\"train shape : {df_train.shape}\")\n","print(f\"test shape : {df_test.shape}\")"]},{"cell_type":"code","source":["df_train.columns #컬럼명 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkiS_6sx8H4z","executionInfo":{"status":"ok","timestamp":1646299420785,"user_tz":-540,"elapsed":12,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"acff8273-d505-4b02-ebe0-8b8f17243368"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'document', 'label'], dtype='object')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.085720Z","start_time":"2022-02-02T04:01:53.081413Z"},"id":"Ql82Ew2VUFxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420786,"user_tz":-540,"elapsed":11,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"381d703b-5cb3-4187-e3ea-aadf95329850"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset len: 10000\n","Train Dataset 1st element: ('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)\n","Test Dataset len: 1000\n","Test Dataset 1st element: ('신용문객잔 보고 후속편인줄 알고 봤더만 완전 개판이네 18.. 이련결 그냥 절에나 쳐 들어 가라.. 회오리에서 싸우는 신 참 가관이더라 .. 서극도 완전 쓰레기 감독이 다 됐구나.. 액션도 쓰레기고 배우들 연기도 참 가관이더라 18', 0)\n"]}],"source":["# Dataset 구현\n","# helper.py에 있는 CustomDataset 활용하여 train datset, test dataset 만들기\n","\"\"\"\n","    - input_data: list of string\n","    - target_data: list of int\n","    \"\"\"\n","train_dataset = CustomDataset(df_train['document'],df_train['label']) #customdataset에 text list와 target list를 입력\n","test_dataset = CustomDataset(df_test['document'],df_test['label'])\n","\n","print(f\"Train Dataset len: {len(train_dataset)}\")\n","print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n","\n","print(f\"Test Dataset len: {len(test_dataset)}\")\n","print(f\"Test Dataset 1st element: {test_dataset[0]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.152070Z","start_time":"2022-02-02T04:01:53.145410Z"},"id":"7WUY6h8WUFxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420786,"user_tz":-540,"elapsed":8,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"84ad1be2-b111-4dea-b6b2-5f406bcb2321"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset len: 9000\n","Valid dataset len: 1000\n"]}],"source":["# Train Dataset을 학습과 검증 셋으로 분리\n","# 학습 셋과 검증 셋의 비율은 9:1\n","# torch.utils.data에서 제공되는 데이터 세트를 임의로 분할할 수 있는 함수 찾아서 사용\n","n_train_sample = df_train.shape[0]\n","\n","n_train = int(n_train_sample*0.9)\n","n_valid = n_train_sample - n_train \n","train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset,[n_train,n_valid]) #train valid split\n","\n","print(f\"Train dataset len: {len(train_dataset)}\")\n","print(f\"Valid dataset len: {len(valid_dataset)}\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"ozrokaMz-S0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:53.268838Z","start_time":"2022-02-02T04:01:53.263780Z"},"id":"H5nc7SpTUFxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299420787,"user_tz":-540,"elapsed":7,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"a3ef4f55-4c5e-4cb1-c920-4fc89c1bbfee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataloader # steps: 282\n","Valid dataloader # steps: 16\n","Test dataloader # steps: 16\n"]}],"source":["# DataLoader 구현\n","# train과 validation의 batch size는 각각 32, 64로 설정\n","# test의 batch size는 validation과 동일\n","# train에 사용할 DataLoader에서는 sampler로 RandomSampler 사용\n","# validation과 test에 사용할 DataLoader에서는 sampler로 SequentialSampler 사용\n","# 모든 DataLoader의 collate_fn은 helper.py에 있는 custom_collate_fn 사용\n","\n","train_batch_size = 32\n","valid_batch_size = 64\n","#dataset 별 dataloader 생성\n","train_dataloader = DataLoader(train_dataset,batch_size=train_batch_size,sampler=RandomSampler(train_dataset),collate_fn=custom_collate_fn) \n","\n","valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch_size,sampler=SequentialSampler(valid_dataset),collate_fn=custom_collate_fn)\n","\n","test_dataloader = DataLoader(test_dataset,batch_size=valid_batch_size,sampler=SequentialSampler(test_dataset),collate_fn=custom_collate_fn)\n","\n","print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n","print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n","print(f\"Test dataloader # steps: {len(test_dataloader)}\")"]},{"cell_type":"markdown","metadata":{"id":"9kEgqvBIUFxN"},"source":["### `auto_grad` 개념 복습\n","- torch의 `auto_grad` 기능\n","    - pytorch는 `requires_grad` 파리미터의 값이 True인 텐서에 한해서 미분값을 자동으로 계산한다.\n","    - 미분값은 `loss.backward()` 가 호출될 때 자동으로 계산된다."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:45:23.502936Z","start_time":"2022-01-31T13:45:20.029987Z"},"id":"oYjYpQ1DUFxN","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["c39189840ee34fa8bae72674a035f1a9","b5be32e41d4c4951a2b0eb3745f66652","e310241a9f594f9bb5949c5ce4392ddc","c88d1c95c50946f696d58a99689ea351","b090915ebf2e4cd79070f0a9db16773e","a8b4703f86b04fb68d762d762af1a636","411a22bac76f4f98b440f06c5126e585","60ddd13ae6d84e5599a549567fe955ba","f117c1d876284454a33db8b7cc6cdcbe","97161af7b40a4290bd2d325192097abe","d54914d138d9446bbecba201687dcac7"]},"executionInfo":{"status":"ok","timestamp":1646299435331,"user_tz":-540,"elapsed":14549,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"af953b10-62bb-4ace-f471-1362e1c4c8e8"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c39189840ee34fa8bae72674a035f1a9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# helper.py에 있는 CustomClassifier 모델을 로드해 model_unfreeze 변수에 instance를 생성\n","hidden_size=768\n","n_label=2\n","\n","\n","model_freeze = CustomClassifier(hidden_size=hidden_size,n_label=n_label) #unfreeze model 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:45:34.604914Z","start_time":"2022-01-31T13:45:34.586711Z"},"id":"XxNFh8KZUFxN"},"outputs":[],"source":["# model_freeze 모델의 모든 파라미터를 출력해보고 아래 질문에 답해 보자"]},{"cell_type":"code","source":["for name, param in model_freeze.named_parameters(): #model_freeze에있는 parameter의 이름과 parameter를 꺼냄\n","    print(f'name:{name}')  #파라미터 이름\n","    print(type(param)) #파라미터가 맞는지\n","    print(f'param.shape:{param.shape}') #shape\n","    print(f'param.requries_grad:{param.requires_grad}') #requires_gard 설정\n","    print(f'param.grad:{param.grad}') #갖고있는 grad\n","    print('=====')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zpm7O468LyLr","executionInfo":{"status":"ok","timestamp":1646299435331,"user_tz":-540,"elapsed":16,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"d02747e6-1dff-4e5d-9be2-4393898e652e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["name:bert.embeddings.word_embeddings.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([32000, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.embeddings.position_embeddings.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([512, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.embeddings.token_type_embeddings.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([2, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.embeddings.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.embeddings.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.0.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.1.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.2.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.3.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.4.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.5.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.6.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.7.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.8.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.9.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.10.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.self.query.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.self.query.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.self.key.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.self.key.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.self.value.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.self.value.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.attention.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.intermediate.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.intermediate.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.output.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 3072])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.output.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.output.LayerNorm.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.encoder.layer.11.output.LayerNorm.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.pooler.dense.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:bert.pooler.dense.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:classifier.0.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([32, 768])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:classifier.0.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([32])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:classifier.3.weight\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([2, 32])\n","param.requries_grad:True\n","param.grad:None\n","=====\n","name:classifier.3.bias\n","<class 'torch.nn.parameter.Parameter'>\n","param.shape:torch.Size([2])\n","param.requries_grad:True\n","param.grad:None\n","=====\n"]}]},{"cell_type":"markdown","metadata":{"id":"KloNNAKI5Q3r"},"source":["### `auto_grad` 개념 및 모델 구조 복습을 위해 다음 항목에 답해 보자\n","name:bert.encoder.layer.0.attention.self.query.weight  \n","<class 'torch.nn.parameter.Parameter'>  \n","param.shape:torch.Size([768, 768])  \n","param.requries_grad:True  \n","- `bert.encoder.layer.0.attention.self.query.weight` 텐서의 gradient는 True인 상태인가?\n","> \n","> ## 정답 : **True**\n","\n","name:classifier.0.weight  \n","<class 'torch.nn.parameter.Parameter'>  \n","param.shape:torch.Size([32, 768])  \n","param.requries_grad:True  \n","param.grad:None\n","- `classifier.0.weight` 텐서의 shape은? \n","> ## 정답 : 32,768\n","- `classifier.0.weight` 텐서는 freeze 상태인가 ? \n","> ## 정답 : unfreeze 상태이다\n","- `classifier.0.weight` 텐서의 gradient 값은 무엇인가? \n","> ## 정답 : None"]},{"cell_type":"markdown","metadata":{"id":"4iIrHg1xUFxP"},"source":["### 위 모델 (`model_freeze`)의 모든 파라미터의 gradient를 freeze 해보자"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-01-31T13:49:26.820569Z","start_time":"2022-01-31T13:49:26.816511Z"},"id":"sHkaFgC8UFxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299435332,"user_tz":-540,"elapsed":14,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"1c3e2e7d-d56b-467d-b18d-4442674fa356"},"outputs":[{"output_type":"stream","name":"stdout","text":["name:bert.embeddings.word_embeddings.weight\n","param.requries_grad:False\n","=====\n","name:bert.embeddings.position_embeddings.weight\n","param.requries_grad:False\n","=====\n","name:bert.embeddings.token_type_embeddings.weight\n","param.requries_grad:False\n","=====\n","name:bert.embeddings.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.embeddings.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.0.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.1.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.2.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.3.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.4.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.5.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.6.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.7.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.8.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.9.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.10.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.self.query.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.self.query.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.self.key.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.self.key.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.self.value.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.self.value.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.attention.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.intermediate.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.intermediate.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.output.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.output.dense.bias\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.output.LayerNorm.weight\n","param.requries_grad:False\n","=====\n","name:bert.encoder.layer.11.output.LayerNorm.bias\n","param.requries_grad:False\n","=====\n","name:bert.pooler.dense.weight\n","param.requries_grad:False\n","=====\n","name:bert.pooler.dense.bias\n","param.requries_grad:False\n","=====\n","name:classifier.0.weight\n","param.requries_grad:False\n","=====\n","name:classifier.0.bias\n","param.requries_grad:False\n","=====\n","name:classifier.3.weight\n","param.requries_grad:False\n","=====\n","name:classifier.3.bias\n","param.requries_grad:False\n","=====\n"]}],"source":["# 모든 파라미터의 gradient를 freeze 해보고 제대로 변경되었는지 확인하기 위해 모델의 모든 파라미터를 출력해보자.\n","\n","for name, param in model_freeze.named_parameters(): #model_freeze에있는 parameter의 이름과 parameter를 꺼냄\n","    print(f'name:{name}')  #파라미터 이름      \n","    param.requires_grad=False #freeze 로 변경\n","    print(f'param.requries_grad:{param.requires_grad}') #requires_gard 설정    \n","    print('=====')\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"NsMgM3sK5Q3t"},"source":["## Challenge"]},{"cell_type":"markdown","metadata":{"id":"vUn-6PFP5Q3t"},"source":["### `scheduler` 를 생성 \n","- 스케쥴러를 알기 전에 먼저 `epoch`의 개념을 알아야 한다. Epoch는 dataset를 **몇 번 반복**해 학습할 것인지를 의미한다. 만약 dataset의 개수가 2,000개이고 epoch을 2번 학습하게 되면 총 4,000개의 데이터를 학습하게 된다.   \n","- 스케쥴러는 epoch에 따라 learning rate의 값을 조정하는 것을 의미한다. \n","- 예를 들어 [여기](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)의 그림에서 볼 수 있듯이 `get_linear_schedule_with_warmup`는 특정 step까지는 learning rate를 천천히 상승시키다가 고점에 도달하면 다시 하락시킨다. "]},{"cell_type":"markdown","metadata":{"id":"_FuADvuT5Q3t"},"source":["### `model`, `optimizer`, `scheduler`를 초기화(=인스턴스 생성)하는 함수를 구현하라"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:59.217735Z","start_time":"2022-02-02T04:01:59.210482Z"},"id":"-sE7xjYcRD1p"},"outputs":[],"source":["from torch.nn import CrossEntropyLoss\n","from torch.optim import AdamW\n","from torch.nn.utils import clip_grad_norm_\n","from transformers import get_linear_schedule_with_warmup, get_constant_schedule"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:01:59.549660Z","start_time":"2022-02-02T04:01:59.545752Z"},"id":"2eTFXzy8VK9R"},"outputs":[],"source":["# model:CustomClassifier 사용, hidden size는 768, label 개수는 2\n","# optimizer: AdamW 사용, learning rate는 2e-5\n","# scheduler: transformers.get_linear_schedule_with_warmup 함수 사용, 단, num_warmup_steps 매개 변수는 사용하지 않음\n","\n","def initializer(train_dataloader, epochs=2):\n","    \"\"\"\n","    모델, 옵티마이저, 스케쥴러를 초기화한 후 반환\n","    \"\"\"\n","    \n","    model = CustomClassifier(768,2)\n","\n","    optimizer = AdamW(model.parameters(),\n","                      lr=2e-5)\n","                                        \n","    \n","    total_steps = len(train_dataloader) * epochs\n","    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n","\n","    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,\n","                                                num_warmup_steps = 0, #아예 안써버리면 오에러남\n","                                                num_training_steps=total_steps)#epoch말고 토탈 스텝을 넣어줘야한다..\n","\n","    return model, optimizer, scheduler"]},{"cell_type":"markdown","metadata":{"id":"Xz-8_5as5Q3u"},"source":["### model, optimizer, scheduler의 파라미터 저장하는 함수를 구현하라"]},{"cell_type":"code","source":["model_freeze.state_dict"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xioCOQJudGs_","executionInfo":{"status":"ok","timestamp":1646299438937,"user_tz":-540,"elapsed":6,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"9ca9dae3-703b-461a-e0a4-1f92aa302fd0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.state_dict of CustomClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=768, out_features=32, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.1, inplace=False)\n","    (3): Linear(in_features=32, out_features=2, bias=True)\n","  )\n",")>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:02:02.786877Z","start_time":"2022-02-02T04:02:02.783726Z"},"id":"vIP1BjFA5Q3u"},"outputs":[],"source":["# 모델 저장 함수 구현\n","#https://discuss.pytorch.org/t/how-to-save-and-load-lr-scheduler-stats-in-pytorch/20208\n","def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n","    file_name = f'{path}/model.ckpt.{epoch}'\n","    \n","    # torch.save 함수 참고\n","    torch.save(\n","        {\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(), \n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(), #()을 꼭 써주자..\n","            'loss' : loss\n","        }, \n","        file_name\n","    )\n","    \n","    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"]},{"cell_type":"markdown","metadata":{"id":"a3BUrgtJ5Q3v"},"source":["### `validate()` 함수 구현 \n","- `validate()` 함수 내 model의 상태는 **evaluate**이어야 한다. evaluate 상태의 model은 dropout을 진행하지 않는다. \n","- **forward**를 진행할 때 `with torch.no_grad(): ...` 설정해 미분 계산을 방지한다.\n"]},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"EV4Kc4mpgQJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:02:11.636684Z","start_time":"2022-02-02T04:02:11.631550Z"},"id":"VHpuV0CXUFxR"},"outputs":[],"source":["# input: model, valid_dataloader\n","# output: loss, 정확도\n","\n","def validate(model, valid_dataloader):\n","    global loss_fct\n","   \n","    # 모델을 evaluate 모드로 설정 & device 할당\n","    model.eval()\n","    \n","    total_loss, total_acc= 0,0\n","        \n","    for step, batch in enumerate(valid_dataloader):\n","        \n","        # tensor 연산 전, 각 tensor에 device 할당\n","        batch = tuple(item.to(device) for item in batch)\n","            \n","        batch_input, batch_label = batch\n","            \n","        # gradient 계산하지 않고 forward 진행\n","        with torch.no_grad():  #검증이라 막아줘야한다\n","            logits = model.forward(**batch_input)\n","            \n","        # loss\n","        loss = loss_fct(logits, batch_label)\n","        total_loss += loss.item()\n","        \n","        # accuracy\n","        probs = F.softmax(logits, dim=1)\n","        preds = torch.argmax(probs, dim=1).flatten()\n","        acc = (preds == batch_label).cpu().numpy().mean()\n","        total_acc+=acc\n","        batch_input.to(device_cpu) #메모리 아웃을 방지하기위해 cpu로 옮김\n","        batch_label.to(device_cpu)\n","\n","    \n","    total_loss = total_loss/(step+1)\n","    total_acc = total_acc/(step+1)*100\n","\n","    return total_loss, total_acc\n"]},{"cell_type":"markdown","metadata":{"id":"NukaJc15UFxQ"},"source":["### `train()` 함수에 `epoch`와 `clip_grad_norm` 추가\n","- data_loader를 `epoch`만큼 반복하면서 학습하도록 `train()` 함수를 수정하라\n","- `gradient cliping`은 미분 값 너무 큰 경우 gradient exploding되는 현상을 막기 위해 미분값이 `threshold`를 넘을 경우 특정 비율을 미분 값에 곱해 크기를 줄여준다.\n","- Reference\n","  - [clip_grad_norm_ official document](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n","  - [그래디언트 클립핑 설명 한국어 블로그](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-6/05-gradient-clipping)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T04:02:10.624280Z","start_time":"2022-02-02T04:02:10.615781Z"},"id":"ZvY5rxDKHQAp"},"outputs":[],"source":["from torch.nn.utils.clip_grad import clip_grad_norm\n","# 위에서 구현한 모델 저장 함수(save_checkpoint)와 validate 함수도 추가해보자\n","\n","loss_fct = CrossEntropyLoss()\n","\n","def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n","        global scheduler, loss_fct\n","        \n","        # train_dataloaer 학습을 epochs만큼 반복\n","        for epoch in range(epochs):\n","            print(f\"*****Epoch {epoch} Train Start*****\")\n","            \n","            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n","            total_loss, batch_loss, batch_count = 0,0,0\n","        \n","            # model을 train 모드로 설정 & device 할당\n","            model.train()\n","            model.to(device)\n","            \n","            # data iterator를 돌면서 하나씩 학습\n","            for step, batch in enumerate(train_dataloader):\n","                batch_count+=1\n","                \n","                # tensor 연산 전, 각 tensor에 device 할당\n","                batch = tuple(item.to(device) for item in batch)\n","            \n","                batch_input, batch_label = batch\n","            \n","                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n","                model.zero_grad()\n","            \n","                # forward\n","                logits = model(**batch_input)\n","            \n","                # loss\n","                loss = loss_fct(logits, batch_label)\n","                batch_loss += loss.item()\n","                total_loss += loss.item()\n","            \n","                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n","                loss.backward()\n","                \n","                # gradient clipping 적용 (max_norm = 1)\n","                clip_grad_norm(model.parameters(), \n","                               max_norm=1)\n","                \n","                # optimizer & scheduler 업데이트\n","                optimizer.step() #optimizer와 scheduler 둘다 step을 줘야한다\n","                scheduler.step()\n","                \n","                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n","                if (step % 10 == 0 and step != 0):\n","                    learning_rate = optimizer.param_groups[0]['lr']\n","                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n","\n","                    # reset \n","                    batch_loss, batch_count = 0,0\n","                batch_input.to(device_cpu)#메모리 아웃 방지 to cpu\n","                batch_label.to(device_cpu)    \n","\n","            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n","            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n","            \n","            if valid_dataloader is not None:\n","                print(f\"*****Epoch {epoch} Valid Start*****\")\n","                valid_loss, valid_acc = validate(model,valid_dataloader)\n","                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n","                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n","            \n","            # checkpoint 저장\n","            save_checkpoint('/content/drive/MyDrive/AI/프리온보딩/2-4check',model,optimizer,scheduler,epoch,loss)\n","                \n","        print(\"Train Completed. End Program.\")"]},{"cell_type":"markdown","metadata":{"id":"4NWKzxIaf1QJ"},"source":["## Advanced"]},{"cell_type":"markdown","metadata":{"id":"gFWnii7a5Q3w"},"source":["### 학습 데이터를 epoch 4까지 학습\n","- 매 epoch마다 다음을 수행한다.\n","  - 학습이 끝난 후 validate() 함수 실행 \n","  - validate() 함수가 끝난 후 model save 함수 실행"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel"],"metadata":{"id":"19QHqfIyotE0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_bert = BertTokenizer.from_pretrained(\"klue/bert-base\")"],"metadata":{"id":"WdAXUgQ-pkIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:02:11.377612Z","start_time":"2022-02-02T04:02:20.931961Z"},"id":"7Er1qKtsf1QJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299839368,"user_tz":-540,"elapsed":398196,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"d2f4c514-3c62-4a68-ad30-02ba8a43c391"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Total train steps with 4 epochs: 1128\n","*****Epoch 0 Train Start*****\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Step : 10, LR : 1.9804964539007094e-05, Avg Loss : 0.6573\n","Epoch: 0, Step : 20, LR : 1.962765957446809e-05, Avg Loss : 0.5602\n","Epoch: 0, Step : 30, LR : 1.945035460992908e-05, Avg Loss : 0.4979\n","Epoch: 0, Step : 40, LR : 1.927304964539007e-05, Avg Loss : 0.4326\n","Epoch: 0, Step : 50, LR : 1.9095744680851064e-05, Avg Loss : 0.3881\n","Epoch: 0, Step : 60, LR : 1.891843971631206e-05, Avg Loss : 0.4225\n","Epoch: 0, Step : 70, LR : 1.8741134751773053e-05, Avg Loss : 0.4150\n","Epoch: 0, Step : 80, LR : 1.8563829787234043e-05, Avg Loss : 0.3981\n","Epoch: 0, Step : 90, LR : 1.8386524822695038e-05, Avg Loss : 0.3459\n","Epoch: 0, Step : 100, LR : 1.8209219858156032e-05, Avg Loss : 0.3662\n","Epoch: 0, Step : 110, LR : 1.8031914893617023e-05, Avg Loss : 0.3939\n","Epoch: 0, Step : 120, LR : 1.7854609929078013e-05, Avg Loss : 0.4043\n","Epoch: 0, Step : 130, LR : 1.7677304964539008e-05, Avg Loss : 0.3979\n","Epoch: 0, Step : 140, LR : 1.7500000000000002e-05, Avg Loss : 0.3547\n","Epoch: 0, Step : 150, LR : 1.7322695035460996e-05, Avg Loss : 0.3631\n","Epoch: 0, Step : 160, LR : 1.7145390070921987e-05, Avg Loss : 0.3868\n","Epoch: 0, Step : 170, LR : 1.696808510638298e-05, Avg Loss : 0.3738\n","Epoch: 0, Step : 180, LR : 1.6790780141843972e-05, Avg Loss : 0.3642\n","Epoch: 0, Step : 190, LR : 1.6613475177304966e-05, Avg Loss : 0.3409\n","Epoch: 0, Step : 200, LR : 1.6436170212765957e-05, Avg Loss : 0.4029\n","Epoch: 0, Step : 210, LR : 1.625886524822695e-05, Avg Loss : 0.3153\n","Epoch: 0, Step : 220, LR : 1.6081560283687945e-05, Avg Loss : 0.3702\n","Epoch: 0, Step : 230, LR : 1.590425531914894e-05, Avg Loss : 0.3327\n","Epoch: 0, Step : 240, LR : 1.572695035460993e-05, Avg Loss : 0.3188\n","Epoch: 0, Step : 250, LR : 1.5549645390070924e-05, Avg Loss : 0.3341\n","Epoch: 0, Step : 260, LR : 1.5372340425531915e-05, Avg Loss : 0.3425\n","Epoch: 0, Step : 270, LR : 1.5195035460992908e-05, Avg Loss : 0.3917\n","Epoch: 0, Step : 280, LR : 1.5017730496453902e-05, Avg Loss : 0.3594\n","Epoch 0 Total Mean Loss : 0.3943\n","*****Epoch 0 Train Finish*****\n","\n","*****Epoch 0 Valid Start*****\n","Epoch 0 Valid Loss : 0.3604 Valid Acc : 84.02\n","*****Epoch 0 Valid Finish*****\n","\n","Saving epoch 0 checkpoint at /content/drive/MyDrive/AI/프리온보딩/2-4check/model.ckpt.0\n","*****Epoch 1 Train Start*****\n","Epoch: 1, Step : 10, LR : 1.4804964539007095e-05, Avg Loss : 0.2075\n","Epoch: 1, Step : 20, LR : 1.4627659574468087e-05, Avg Loss : 0.2585\n","Epoch: 1, Step : 30, LR : 1.4450354609929078e-05, Avg Loss : 0.2121\n","Epoch: 1, Step : 40, LR : 1.427304964539007e-05, Avg Loss : 0.2496\n","Epoch: 1, Step : 50, LR : 1.4095744680851065e-05, Avg Loss : 0.2304\n","Epoch: 1, Step : 60, LR : 1.3918439716312057e-05, Avg Loss : 0.2631\n","Epoch: 1, Step : 70, LR : 1.3741134751773051e-05, Avg Loss : 0.2695\n","Epoch: 1, Step : 80, LR : 1.3563829787234044e-05, Avg Loss : 0.2527\n","Epoch: 1, Step : 90, LR : 1.3386524822695038e-05, Avg Loss : 0.3183\n","Epoch: 1, Step : 100, LR : 1.320921985815603e-05, Avg Loss : 0.2110\n","Epoch: 1, Step : 110, LR : 1.3031914893617021e-05, Avg Loss : 0.2421\n","Epoch: 1, Step : 120, LR : 1.2854609929078014e-05, Avg Loss : 0.2573\n","Epoch: 1, Step : 130, LR : 1.2677304964539008e-05, Avg Loss : 0.2920\n","Epoch: 1, Step : 140, LR : 1.25e-05, Avg Loss : 0.2075\n","Epoch: 1, Step : 150, LR : 1.2322695035460995e-05, Avg Loss : 0.1729\n","Epoch: 1, Step : 160, LR : 1.2145390070921987e-05, Avg Loss : 0.2249\n","Epoch: 1, Step : 170, LR : 1.196808510638298e-05, Avg Loss : 0.3076\n","Epoch: 1, Step : 180, LR : 1.1790780141843972e-05, Avg Loss : 0.3353\n","Epoch: 1, Step : 190, LR : 1.1613475177304965e-05, Avg Loss : 0.2101\n","Epoch: 1, Step : 200, LR : 1.1436170212765957e-05, Avg Loss : 0.1842\n","Epoch: 1, Step : 210, LR : 1.1258865248226952e-05, Avg Loss : 0.2979\n","Epoch: 1, Step : 220, LR : 1.1081560283687944e-05, Avg Loss : 0.2188\n","Epoch: 1, Step : 230, LR : 1.0904255319148938e-05, Avg Loss : 0.3023\n","Epoch: 1, Step : 240, LR : 1.072695035460993e-05, Avg Loss : 0.2420\n","Epoch: 1, Step : 250, LR : 1.0549645390070923e-05, Avg Loss : 0.2722\n","Epoch: 1, Step : 260, LR : 1.0372340425531916e-05, Avg Loss : 0.2090\n","Epoch: 1, Step : 270, LR : 1.0195035460992908e-05, Avg Loss : 0.2409\n","Epoch: 1, Step : 280, LR : 1.00177304964539e-05, Avg Loss : 0.2717\n","Epoch 1 Total Mean Loss : 0.2486\n","*****Epoch 1 Train Finish*****\n","\n","*****Epoch 1 Valid Start*****\n","Epoch 1 Valid Loss : 0.3765 Valid Acc : 84.45\n","*****Epoch 1 Valid Finish*****\n","\n","Saving epoch 1 checkpoint at /content/drive/MyDrive/AI/프리온보딩/2-4check/model.ckpt.1\n","*****Epoch 2 Train Start*****\n","Epoch: 2, Step : 10, LR : 9.804964539007093e-06, Avg Loss : 0.1985\n","Epoch: 2, Step : 20, LR : 9.627659574468086e-06, Avg Loss : 0.1831\n","Epoch: 2, Step : 30, LR : 9.450354609929078e-06, Avg Loss : 0.1683\n","Epoch: 2, Step : 40, LR : 9.273049645390073e-06, Avg Loss : 0.1744\n","Epoch: 2, Step : 50, LR : 9.095744680851063e-06, Avg Loss : 0.1746\n","Epoch: 2, Step : 60, LR : 8.918439716312058e-06, Avg Loss : 0.1749\n","Epoch: 2, Step : 70, LR : 8.74113475177305e-06, Avg Loss : 0.1585\n","Epoch: 2, Step : 80, LR : 8.563829787234044e-06, Avg Loss : 0.1481\n","Epoch: 2, Step : 90, LR : 8.386524822695035e-06, Avg Loss : 0.1381\n","Epoch: 2, Step : 100, LR : 8.20921985815603e-06, Avg Loss : 0.1547\n","Epoch: 2, Step : 110, LR : 8.031914893617022e-06, Avg Loss : 0.1838\n","Epoch: 2, Step : 120, LR : 7.854609929078016e-06, Avg Loss : 0.1459\n","Epoch: 2, Step : 130, LR : 7.677304964539007e-06, Avg Loss : 0.1892\n","Epoch: 2, Step : 140, LR : 7.500000000000001e-06, Avg Loss : 0.1616\n","Epoch: 2, Step : 150, LR : 7.3226950354609935e-06, Avg Loss : 0.1510\n","Epoch: 2, Step : 160, LR : 7.145390070921986e-06, Avg Loss : 0.1680\n","Epoch: 2, Step : 170, LR : 6.968085106382979e-06, Avg Loss : 0.1855\n","Epoch: 2, Step : 180, LR : 6.790780141843972e-06, Avg Loss : 0.1432\n","Epoch: 2, Step : 190, LR : 6.613475177304965e-06, Avg Loss : 0.1360\n","Epoch: 2, Step : 200, LR : 6.436170212765958e-06, Avg Loss : 0.1085\n","Epoch: 2, Step : 210, LR : 6.258865248226951e-06, Avg Loss : 0.1922\n","Epoch: 2, Step : 220, LR : 6.081560283687944e-06, Avg Loss : 0.2039\n","Epoch: 2, Step : 230, LR : 5.904255319148937e-06, Avg Loss : 0.2061\n","Epoch: 2, Step : 240, LR : 5.7269503546099295e-06, Avg Loss : 0.0798\n","Epoch: 2, Step : 250, LR : 5.549645390070923e-06, Avg Loss : 0.1023\n","Epoch: 2, Step : 260, LR : 5.372340425531915e-06, Avg Loss : 0.1311\n","Epoch: 2, Step : 270, LR : 5.195035460992908e-06, Avg Loss : 0.2458\n","Epoch: 2, Step : 280, LR : 5.017730496453901e-06, Avg Loss : 0.1790\n","Epoch 2 Total Mean Loss : 0.1634\n","*****Epoch 2 Train Finish*****\n","\n","*****Epoch 2 Valid Start*****\n","Epoch 2 Valid Loss : 0.4295 Valid Acc : 84.96\n","*****Epoch 2 Valid Finish*****\n","\n","Saving epoch 2 checkpoint at /content/drive/MyDrive/AI/프리온보딩/2-4check/model.ckpt.2\n","*****Epoch 3 Train Start*****\n","Epoch: 3, Step : 10, LR : 4.804964539007093e-06, Avg Loss : 0.0980\n","Epoch: 3, Step : 20, LR : 4.6276595744680855e-06, Avg Loss : 0.0882\n","Epoch: 3, Step : 30, LR : 4.450354609929078e-06, Avg Loss : 0.1186\n","Epoch: 3, Step : 40, LR : 4.273049645390071e-06, Avg Loss : 0.1248\n","Epoch: 3, Step : 50, LR : 4.095744680851064e-06, Avg Loss : 0.0989\n","Epoch: 3, Step : 60, LR : 3.918439716312057e-06, Avg Loss : 0.0711\n","Epoch: 3, Step : 70, LR : 3.74113475177305e-06, Avg Loss : 0.0978\n","Epoch: 3, Step : 80, LR : 3.5638297872340426e-06, Avg Loss : 0.1607\n","Epoch: 3, Step : 90, LR : 3.386524822695036e-06, Avg Loss : 0.0873\n","Epoch: 3, Step : 100, LR : 3.2092198581560285e-06, Avg Loss : 0.1192\n","Epoch: 3, Step : 110, LR : 3.031914893617022e-06, Avg Loss : 0.1055\n","Epoch: 3, Step : 120, LR : 2.8546099290780144e-06, Avg Loss : 0.0968\n","Epoch: 3, Step : 130, LR : 2.6773049645390077e-06, Avg Loss : 0.1139\n","Epoch: 3, Step : 140, LR : 2.5e-06, Avg Loss : 0.2277\n","Epoch: 3, Step : 150, LR : 2.322695035460993e-06, Avg Loss : 0.0879\n","Epoch: 3, Step : 160, LR : 2.145390070921986e-06, Avg Loss : 0.1245\n","Epoch: 3, Step : 170, LR : 1.968085106382979e-06, Avg Loss : 0.1007\n","Epoch: 3, Step : 180, LR : 1.790780141843972e-06, Avg Loss : 0.1246\n","Epoch: 3, Step : 190, LR : 1.6134751773049648e-06, Avg Loss : 0.1420\n","Epoch: 3, Step : 200, LR : 1.4361702127659578e-06, Avg Loss : 0.1129\n","Epoch: 3, Step : 210, LR : 1.2588652482269503e-06, Avg Loss : 0.0809\n","Epoch: 3, Step : 220, LR : 1.0815602836879434e-06, Avg Loss : 0.0623\n","Epoch: 3, Step : 230, LR : 9.042553191489363e-07, Avg Loss : 0.1007\n","Epoch: 3, Step : 240, LR : 7.26950354609929e-07, Avg Loss : 0.1372\n","Epoch: 3, Step : 250, LR : 5.496453900709221e-07, Avg Loss : 0.1179\n","Epoch: 3, Step : 260, LR : 3.723404255319149e-07, Avg Loss : 0.1205\n","Epoch: 3, Step : 270, LR : 1.9503546099290782e-07, Avg Loss : 0.1522\n","Epoch: 3, Step : 280, LR : 1.773049645390071e-08, Avg Loss : 0.0693\n","Epoch 3 Total Mean Loss : 0.1124\n","*****Epoch 3 Train Finish*****\n","\n","*****Epoch 3 Valid Start*****\n","Epoch 3 Valid Loss : 0.4700 Valid Acc : 85.25\n","*****Epoch 3 Valid Finish*****\n","\n","Saving epoch 3 checkpoint at /content/drive/MyDrive/AI/프리온보딩/2-4check/model.ckpt.3\n","Train Completed. End Program.\n"]}],"source":["# 4 epoch 학습\n","epochs=4\n","model, optimizer, scheduler = initializer(train_dataloader, epochs) #인스턴트 모델\n","train(model, train_dataloader, valid_dataloader, epochs)"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2022-02-02T03:27:18.246441Z","start_time":"2022-02-02T03:27:18.236617Z"},"id":"vA3_vqqCXccc"},"source":["### 가장 dev acc 성능이 높았던 epoch의 모델의 체크 포인트를 불러와 로드하자"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:27.646150Z","start_time":"2022-02-02T06:22:26.945572Z"},"id":"mvfkSff25Q3z"},"outputs":[],"source":["# torch.load 함수 사용\n","\n","checkpoint = torch.load('/content/drive/MyDrive/AI/프리온보딩/2-4check/model.ckpt.3')"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:36.415665Z","start_time":"2022-02-02T06:22:36.407250Z"},"id":"YqcxMmTj5Q3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299841550,"user_tz":-540,"elapsed":10,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"e8dc51aa-11ee-43ca-ee6f-d368fcb6abdc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"]},"metadata":{},"execution_count":33}],"source":["# checkpoint의 key 종류를 확인\n","checkpoint.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:40.272939Z","start_time":"2022-02-02T06:22:37.010491Z"},"id":"wTvFYgNi5Q30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299843815,"user_tz":-540,"elapsed":2273,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"fa1f7d2a-54fe-41b0-bd62-1beed232cdbd"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Total train steps with 1 epochs: 282\n"]}],"source":["# 위에서 구현한 initializer 함수 사용하여 model, optimizer, scheduler 초기화\n","\n","epochs=1\n","model, optimizer, scheduler = initializer(train_dataloader,epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:40.443912Z","start_time":"2022-02-02T06:22:40.274323Z"},"id":"CtR2sTW55Q30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646299843815,"user_tz":-540,"elapsed":7,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"045841c6-b5ec-4aa8-a8af-037314f58a7d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":35}],"source":["model.load_state_dict(checkpoint[\"model_state_dict\"]) #체크포인트 로드"]},{"cell_type":"markdown","metadata":{"id":"Tzske7SR5Q30"},"source":["### 모델 예측 함수 구현\n","- test_dataloader를 입력받아 모델이 예측한 확률값 (probs)과 실제 정답 (label) 을 출력하는 `\bpredict()` 함수를 구현하자.\n","- 함수 정의\n","  - 입력 매개변수\n","    - `model` : `CustomClassifier` 모델. logits를 반환함 \n","    - `test_dataloader` : test 데이터셋의 텍스트와 레이블을 배치로 갖는 dataloader\n","  - 조건\n","    - `test_dataloader`는 이터레이터기 때문에 이터레이터를 순회하면서 `all_logits` 리스트에 배치 단위의 logits를 저장하고 `all_labels` 리스트에 배치 단위의 레이블 (0 또는 1 값)을 저장하라\n","  - 반환값\n","    - `probs`\n","      - logits에 softmax 함수를 취한 확률값. (test data 개수, label 개수) shape을 가짐. \bnp.array 타입으로 데이터 타입을 변환할 것.\n","    - `labels`\n","      - 0 또는 1 값을 갖는 np.array. (test data 개수,) shape을 가짐."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:48.062229Z","start_time":"2022-02-02T06:22:48.057531Z"},"id":"yQ7WiD1Oigg9"},"outputs":[],"source":["def predict(model, test_dataloader):\n","    \"\"\"\n","    test_dataloader의 label별 확률값과 실제 label 값을 반환\n","    \"\"\"\n","\n","    # model을 eval 모드로 설정 & device 할당\n","    model.eval()\n","    model.to(device)\n","\n","    all_logits = []\n","    all_labels = []\n","\n","    for step, batch in enumerate(test_dataloader):\n","        \n","        batch_input, batch_label = batch\n","        \n","        # batch_input을 device 할당\n","        batch_input.to(device)\n","\n","        # model에 batch_input을 넣어 logit 반환 & all_logits, all_labels 리스트에 값 추가 \n","        with torch.no_grad(): #검증과 마찬가지로 gredient 계산을 막음\n","            logits = model.forward(**batch_input)        \n","\n","        all_logits.append(logits)\n","        all_labels.append(batch_label)\n","\n","        logits.to(device_cpu)#메모리 아웃방지\n","   \n","    \n","\n","    # logits을 확률값으로 변환 & Tensor 타입을 numpy.array 타입으로 변환      \n","    probs=F.softmax(torch.cat(all_logits,dim=0),dim=1).to(device_cpu).numpy() #모아진 tensor들을 concat => 확률화 => to cpu =>numpy\n","    \n","    all_labels =torch.cat(all_labels,dim=0).to(device_cpu).numpy()#  Tensor 타입을 numpy.array 타입으로 변환\n","\n","    return probs, all_labels\n","\n"]},{"cell_type":"markdown","source":["- 모델이 예측한 확률값과 실제 label을 입력 받아 정확도를 출력하는 **accuracy()** 함수를 구현하자. \n","- 함수 정의 \n","  - 입력 매개변수 \n","    - `probs` : `predict()` 함수의 반환값. 2차원의 np.array\n","    - `labels` : `predict()` 함수의 반환값. 1차원의 np.array\n","  - 조건\n","    - `probs`의 확률값이 0.5 이상이면 1, 이하이면 0이 되도록 만든다. 모델이 예측한 레이블을 실제값(`labels`)과 비교해 예측값과 실제값이 같으면 1, 다르면 0 점수를 준다. 모든 데이터에 대해 점수의 평균값이 accuracy 값이다. \n","  - 반환값 \n","    - `acc` : 정확도 (Float type)"],"metadata":{"id":"lOxCjZ2g6ZeK"}},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:22:48.296419Z","start_time":"2022-02-02T06:22:48.293737Z"},"id":"42-umZ3m5Q32"},"outputs":[],"source":["# accuracy 함수 구현\n","def accuracy(probs, labels):   \n","    y_pred = np.where(probs[:,1] < 0.5, 0, 1) # probs(확률값)을 label로 변경(0.5 이상이면 1, 0.5 미만이면 0)     \n","    right,all=0,0    \n","    for pred,label in zip(y_pred,labels):#정확도 계산\n","        right += pred == label \n","        all+=1\n","    acc=right/all\n","    return acc \n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:22.752497Z","start_time":"2022-02-02T06:22:48.652784Z"},"id":"SwkrRPAhjsXb"},"outputs":[],"source":["probs, labels = predict(model, test_dataloader)"]},{"cell_type":"code","source":["threshold =0.5\n","accuracy(probs,labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKUd-z26gvAX","executionInfo":{"status":"ok","timestamp":1646310351302,"user_tz":-540,"elapsed":281,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"outputId":"b3fd6d9e-c928-4aab-ebe8-49074393803d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.863"]},"metadata":{},"execution_count":167}]},{"cell_type":"markdown","metadata":{"id":"3mqUfkx-5Q33"},"source":["### `sklearn.metrics`의 `accuracy_score`, `roc_auc_score` 함수를 이용해 정확도와 auc를 계산하라"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:23.111879Z","start_time":"2022-02-02T06:24:22.760568Z"},"id":"VFWj4lcp5Q33"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:23.116872Z","start_time":"2022-02-02T06:24:23.113064Z"},"id":"p9BEe2mflTem","executionInfo":{"status":"ok","timestamp":1646310349053,"user_tz":-540,"elapsed":296,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6032b90c-49c7-4be1-e501-bf73c46a06ab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.863"]},"metadata":{},"execution_count":166}],"source":["# 정확도 출력\n","accuracy_score(labels,np.where(probs[:,1] < 0.5, 0, 1))\n","#만든 accuracy함수 0.863과 동일"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-02T06:24:23.125650Z","start_time":"2022-02-02T06:24:23.117847Z"},"id":"oCl6BiPGpCPW","executionInfo":{"status":"ok","timestamp":1646310172292,"user_tz":-540,"elapsed":291,"user":{"displayName":"김석재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinQOomWONmt82tKAM95-_bF9gvg7EPjUXHZ02Hu4s=s64","userId":"05383809141048124324"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cd5c581-b7cb-4730-8b32-9173bec3d956"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.932226"]},"metadata":{},"execution_count":163}],"source":["# auc 출력\n","roc_auc_score(labels,probs[:,1])"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"7팀 김석재 2-4.ipynb","provenance":[{"file_id":"1EnHpbMFI89BYbD4mJ8kbeXtmFV7esuUO","timestamp":1646277685184}],"machine_shape":"hm"},"kernelspec":{"display_name":"torch","language":"python","name":"torch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fb56d92e7fad4206a5d02bb72e37e8e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_907ec485efa34068a0d7e35d533baf79","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3602f5deadef4d7daffeee229663361d","IPY_MODEL_111c7e7402514c7b9ef6ece192f52a01","IPY_MODEL_57f850358d4b4e438684fb39a5ce02ab"]}},"907ec485efa34068a0d7e35d533baf79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3602f5deadef4d7daffeee229663361d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0395996c354c45d3bc33b8984d4c44c9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_778d829c34344c8a9cd6dd0f2dc7eaf7"}},"111c7e7402514c7b9ef6ece192f52a01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ad8a84ee431044ce82ac5a5b2efe5777","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01a4f5845e2f48f1b2fa3c8a64495482"}},"57f850358d4b4e438684fb39a5ce02ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2dba744c74ae4d1ebdc0c9d2a4feb5d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 289/289 [00:00&lt;00:00, 8.29kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb5e02bad0dd442f939bada7421c4653"}},"0395996c354c45d3bc33b8984d4c44c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"778d829c34344c8a9cd6dd0f2dc7eaf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad8a84ee431044ce82ac5a5b2efe5777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"01a4f5845e2f48f1b2fa3c8a64495482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2dba744c74ae4d1ebdc0c9d2a4feb5d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb5e02bad0dd442f939bada7421c4653":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56ab89c5452d4135b07d2c1e24a44051":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ecd16f084494944833b53fed089275d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c05528d675cc4675bbe74db06b1791f1","IPY_MODEL_34487c70973b46828a77658aec20ad24","IPY_MODEL_dc90354839da45b9936cfbe04004a033"]}},"8ecd16f084494944833b53fed089275d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c05528d675cc4675bbe74db06b1791f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_defb3edc5b3e4b73bd1f563330309d77","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c21031be7a984593ad6f5fcc128da3bf"}},"34487c70973b46828a77658aec20ad24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b9f3d805ae3946f595ca4fcaca393fe9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":248477,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":248477,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c536f4c37cf4d89977975716388549e"}},"dc90354839da45b9936cfbe04004a033":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_519fb7be4c7340169ee89fb60d376f87","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243k/243k [00:00&lt;00:00, 721kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d808579114c54383b95d5c744bd3d6e2"}},"defb3edc5b3e4b73bd1f563330309d77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c21031be7a984593ad6f5fcc128da3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9f3d805ae3946f595ca4fcaca393fe9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5c536f4c37cf4d89977975716388549e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"519fb7be4c7340169ee89fb60d376f87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d808579114c54383b95d5c744bd3d6e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c9c122a8a4848208eeb1850e0a692ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb8654c144fa46a18358a7dbe80db675","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9cb7c2e5f63c4238b354650f43c754e9","IPY_MODEL_5ac52b403cdc469f9e5d7e06b563c1aa","IPY_MODEL_823d7ae43042483c9b421ccc1188e835"]}},"bb8654c144fa46a18358a7dbe80db675":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cb7c2e5f63c4238b354650f43c754e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d75dcb8a53e494a92c34906c004ce03","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb80a428a04840bd8c88de5dfb94458e"}},"5ac52b403cdc469f9e5d7e06b563c1aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_27557c8a6d094261bff995a57e9ce34a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ebf9df932b84ed5ac9e313568f31cf2"}},"823d7ae43042483c9b421ccc1188e835":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_164da745095748e5bbdc97b8cb8504b9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [00:00&lt;00:00, 4.18kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd4fd86cd33f4b84afcccec1c744b2e8"}},"3d75dcb8a53e494a92c34906c004ce03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb80a428a04840bd8c88de5dfb94458e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27557c8a6d094261bff995a57e9ce34a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4ebf9df932b84ed5ac9e313568f31cf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"164da745095748e5bbdc97b8cb8504b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd4fd86cd33f4b84afcccec1c744b2e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db6346723d1443b8a910b4c47ec68cb6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_27113815b0694b78897bad22a06d9833","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_978b061973634d42b49a9e788ce85555","IPY_MODEL_13d112fc5a7149b8a25c9fc275ba5c98","IPY_MODEL_ac6acfec8de847b5b56940759b8742e9"]}},"27113815b0694b78897bad22a06d9833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"978b061973634d42b49a9e788ce85555":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_185d8141487a4420afd47324bdc4add0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e205d0fc626a4643b1b467b54ad5ba96"}},"13d112fc5a7149b8a25c9fc275ba5c98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_982bfdd5b88442c8916c70975016b06a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":494860,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":494860,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea900201c92e4a96863de226592232d7"}},"ac6acfec8de847b5b56940759b8742e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4918a0d230a4ad6974f202060057002","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 483k/483k [00:00&lt;00:00, 804kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9361b99bab384ad3a5797164a3ee37e7"}},"185d8141487a4420afd47324bdc4add0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e205d0fc626a4643b1b467b54ad5ba96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"982bfdd5b88442c8916c70975016b06a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea900201c92e4a96863de226592232d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4918a0d230a4ad6974f202060057002":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9361b99bab384ad3a5797164a3ee37e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74629b4255a34da09920dbe94c4ff0c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2d80c64b44254f5e9a283d97d017b037","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1f538c6d6d194608b79e385538410053","IPY_MODEL_cf423e8cc01d49f698f265bab62631d6","IPY_MODEL_8a6e28e914de42d5bb952bb113da551f"]}},"2d80c64b44254f5e9a283d97d017b037":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f538c6d6d194608b79e385538410053":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d3d9ae021764ab4abbaafe220ee35e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_010e81876d19415f978a4c3f802bb5fb"}},"cf423e8cc01d49f698f265bab62631d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a79e710dae3d419494f71549c721ce61","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":425,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":425,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f34b0237b30a42dfb767b4c4c27b2a31"}},"8a6e28e914de42d5bb952bb113da551f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5b816392dce4f188995f430d3bffaeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 425/425 [00:00&lt;00:00, 12.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba77ae9c18e645549e727b7dfd2744c0"}},"4d3d9ae021764ab4abbaafe220ee35e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"010e81876d19415f978a4c3f802bb5fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a79e710dae3d419494f71549c721ce61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f34b0237b30a42dfb767b4c4c27b2a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5b816392dce4f188995f430d3bffaeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba77ae9c18e645549e727b7dfd2744c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c39189840ee34fa8bae72674a035f1a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b5be32e41d4c4951a2b0eb3745f66652","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e310241a9f594f9bb5949c5ce4392ddc","IPY_MODEL_c88d1c95c50946f696d58a99689ea351","IPY_MODEL_b090915ebf2e4cd79070f0a9db16773e"]}},"b5be32e41d4c4951a2b0eb3745f66652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e310241a9f594f9bb5949c5ce4392ddc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a8b4703f86b04fb68d762d762af1a636","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_411a22bac76f4f98b440f06c5126e585"}},"c88d1c95c50946f696d58a99689ea351":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_60ddd13ae6d84e5599a549567fe955ba","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":445025130,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":445025130,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f117c1d876284454a33db8b7cc6cdcbe"}},"b090915ebf2e4cd79070f0a9db16773e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_97161af7b40a4290bd2d325192097abe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 424M/424M [00:11&lt;00:00, 31.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d54914d138d9446bbecba201687dcac7"}},"a8b4703f86b04fb68d762d762af1a636":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"411a22bac76f4f98b440f06c5126e585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60ddd13ae6d84e5599a549567fe955ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f117c1d876284454a33db8b7cc6cdcbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97161af7b40a4290bd2d325192097abe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d54914d138d9446bbecba201687dcac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}